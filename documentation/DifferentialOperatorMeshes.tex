\documentclass[]{article}

\usepackage[latin1]{inputenc}
\usepackage[english]{babel} 
\usepackage[dvips]{graphicx} 
\usepackage{amsmath} 
\usepackage{geometry}
\usepackage{amsfonts}
\usepackage{amssymb} 
\usepackage{mathrsfs}
%\usepackage{unicode-math}
\usepackage[final]{pdfpages}
\usepackage{sidecap}
%\usepackage{subfigure}
\usepackage{hyperref}
\usepackage[makeroom]{cancel}
\usepackage{subfig}


\newcommand{\p}{\partial}
\newcommand{\nb}{\bs{\nabla}}
\newcommand{\bt}[1]{\textbf{#1}}
\newcommand{\tx}[1]{\text{#1}}
\newcommand{\mt}[1]{\mathrm{#1}}
\newcommand{\bs}[1]{\boldsymbol{#1}}
\newcommand{\mc}[1]{\mathcal{#1}}
\newcommand{\e}[1]{\hat{\bs{e}}_{#1}}
\newcommand{\Eq}[1]{\begin{equation}#1\end{equation}}
\newcommand{\HalfFig}[1]{\includegraphics[width=65mm]{#1}}
\newcommand{\FullFig}[1]{\includegraphics[width=150mm]{#1}}
\bibliographystyle{plain}
\definecolor{linkcol}{rgb}{0,0,1}
\definecolor{citecol}{rgb}{0,0,1}
\newcommand{\RED}[1]{\textcolor{red}{#1}}
\newcommand{\BLUE}[1]{\textcolor{blue}{#1}}
% Change this to change the informations included in the pdf file
% See hyperref documentation for information on those parameters
%\usepackage{hyperref}
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=magenta,      
    urlcolor=blue,
}

\begin{document}
\section*{Differential operators on polyhedral unstructured meshes}
\subsection*{Goal}
Let us consider a scalar function $\phi:\mathbb{R}^3 \rightarrow \mathbb{R}$, and a mesh composed by $N$ polyhedral cells $\{c_i\}_{1,\dots,N}$. We assume to know the value of $\phi$ on each cell. We denote by $\phi_i$ the value of $\phi$ on the $i^{\text{\scriptsize th}}$ cell.  Similarly, we denote by $(\partial_x \phi)_i$ the value of the $x$ derivative of $\phi$  on the $i^{\text{\scriptsize th}}$ cell. The goal is to construct a matrix $D^{(x)}$ which calculates the $x$ derivative:
\Eq{(\partial_x \phi)_i = \sum_j D^{(x)}_{ij} \phi_j}
and similarly for the $y$ and $z$ derivatives.
\subsection*{Concept}
The method is based on the Green-Gauss theorem (see Sec.~III.A of Ref.~\cite{Sozer2014}). The average gradient of $\phi$ over one cell is:
\Eq{(\overline{ \bs{\nabla}\phi})_i  =\frac{1}{V_i} \int_{c_i} dV  \bs{\nabla}\phi = \frac{1}{V_i}  \oint_{\partial c_i} dA\, \phi \, \hat{\bs{n}}}
where $V_i$ denotes the volume of a cell, $\partial c_i$ the external surface, and $ \hat{\bs{n}}$ the unit vector normal to the surface at a given point. %The $x$, $y$, and $z$ derivative are obtained from the gradient by 
For a polyhedral cell we have:
 \Eq{(\overline{ \bs{\nabla}\phi})_i  \rightarrow  \frac{1}{V_i} \sum_f  \overline{\phi}_f  \hat{\bs{n}}_f A_f\label{eq:TheGradient1}}
where the index $f$ runs over the external faces of the $i^{\text{\scriptsize th}}$ cell, $ \hat{\bs{n}}_f$ denotes the  unit vector normal to the  $f^{\text{\scriptsize th}}$ face, $A_f$ its area, and $\overline{\phi}_f $ is the average value of $\phi$ over the face. It is thus necessary to evaluate the face average $\overline{\phi}_f $. As pointed out in  Ref.~\cite{Sozer2014}, several alternative methods exist, the simplest being averaging the two values assumed by $\phi$ over the the two cells $i$ and $i'$ that share the face $f$ (see Sec.~III.A.1 of Ref.~\cite{Sozer2014}).
\subsection*{Implementation}
%Let us not consider the boundaries for now. This assumption means that each face is shared by exactly two cells.
The set of all the normal vectors to the faces is denoted by:
\Eq{\{ \hat{\bs{n}}_f\}  }
We introduce the matrix $B$ having number of rows equal to the total number of faces, and number of columns equal to the total number of cells. The entry $B_{f j}$ is equal to $+1$ if the face $f$ belongs to the cell $j$ and the normal is direct outwards, is equal to  $-1$ if the face $f$ belongs to the cell $j$ and the normal is direct inwards,  and is equal to $0$ otherwise (i.e. if the face $f$ does not belong to the cell $j$).
By letting the index $f$ run over \emph{all} the faces (instead of only those belonging to the $i^{\text{\scriptsize th}}$ cell), we can modify Eq.~\ref{eq:TheGradient1}:
 \Eq{(\overline{ \bs{\nabla}\phi})_i =  \frac{1}{V_i} \sum_f B_{fi}  \overline{\phi}_f  \hat{\bs{n}}_f A_f \label{eq:TheGradient2}}
As mentioned, we can calculate  $\overline{\phi}_f $ by averaging the value of $\phi$ over the two cells adjacent to the face $f$:
\Eq{ \overline{\phi}_f  = \frac{1}{\sum_h |B_{fh}|}\sum_j |B_{fj}| \phi_j \label{eq:FaceAvrg}}
The quantity $\sum_h |B_{fh}|$ corresponds to the number of cells sharing the face $f$, (i.e. $2$ is the face is shared between two cells, and $1$ if the face is on the boundary).
Plugging Eq.~\ref{eq:FaceAvrg} into Eq.~\ref{eq:TheGradient2} we get:
 \Eq{(\overline{ \bs{\nabla}\phi})_i =  \frac{1}{V_i} \sum_f B_{fi} \hat{\bs{n}}_f A_f  \frac{1}{\sum_h |B_{fh}|}\sum_j |B_{fj}| \phi_j  = \sum_j \bs{D}_{ij}\phi_j }
with
 \Eq{  \bs{D}_{ij}  =  \frac{1}{V_i} \sum_f B_{fi} \hat{\bs{n}}_f A_f  \frac{1}{\sum_h |B_{fh}|}| B_{fj} |}
The matrix $D^{(x)}$ is obtained from $ \bs{D}$ by taking the scalar product with the unit vector $\hat{\bs{e}}_x$, and similarly for the $y$ and $z$ components of the gradient.
\subsection*{Least Squares Interpolation}
It can be shown (Sec.~IV.B of Ref.~\cite{Sozer2014}) that the na{\"\i}ve averaging approach discussed above carries a zero'th order error term for non-uniform cell spacing, that is, though the estimated face value $\overline{\phi}_f $ converges as the cell size becomes infinitely small, it does not converge to the correct value. A slightly more sophisticated method follows from Taylor expanding the value $\phi_i$ at the $i^{th}$ cell around the center of the face,
\Eq{\phi_i = \phi_f + \Delta x_i\phi_{f,x} + \Delta y_i\phi_{f,y} + \Delta z_i\phi_{f,z} + \dots,}
where $\dots$ refers to higher order terms. If we introduce the functional
\Eq{F(w_i,\phi_i,\phi_{f,x},\phi_{f,y},\phi_{f,z},\dots) = \sum_{i=1}^N w_i\left[\Delta\phi_i + \Delta x_i\phi_{f,x} + \Delta y_i\phi_{f,y} + \Delta z_i\phi_{f,z} + \dots\right]^2,}
where $w_i$ are user-defined weights for each point $i$ and $\Delta\phi_i = \phi_f - \phi_i$, then all of the following is standard procedure for the least squares method. Minimizing $F$ yields the equations
\Eq{\frac{\p F}{\p \phi_f} =  \sum_{i=1}^N 2 w_i\left[\Delta\phi_i + \Delta x_i\phi_{f,x} + \Delta y_i\phi_{f,y} + \Delta z_i\phi_{f,z} + \dots\right] = 0}
\Eq{\frac{\p F}{\p \phi_{f,x}} =  \sum_{i=1}^N 2 w_i\Delta x\left[\Delta\phi_i + \Delta x_i\phi_{f,x} + \Delta y_i\phi_{f,y} + \Delta z_i\phi_{f,z} + \dots\right] = 0}
\Eq{\frac{\p F}{\p \phi_{f,y}} =  \sum_{i=1}^N 2 w_i\Delta y\left[\Delta\phi_i + \Delta x_i\phi_{f,x} + \Delta y_i\phi_{f,y} + \Delta z_i\phi_{f,z} + \dots\right] = 0}
\Eq{\frac{\p F}{\p \phi_{f,z}} =  \sum_{i=1}^N 2 w_i\Delta z\left[\Delta\phi_i + \Delta x_i\phi_{f,x} + \Delta y_i\phi_{f,y} + \Delta z_i\phi_{f,z} + \dots\right] = 0}
which allow us to write up a linear system of equations,
\Eq{G\Phi_f = H\phi \rightarrow \Phi_f = G^{-1}H\phi,\label{eq:FaceLeastSquares}}
where $\Phi_f = [\phi_f,\phi_{f,x},\phi_{f,y},\phi_{f,z}]^T$, $\phi = [\phi_1,\phi_2,\dots,\phi_i,\dots,\phi_N]$,
\Eq{G =
\begin{bmatrix}
    \sum w_i       & \sum w_i \Delta x_i & \sum w_i \Delta y_i & \sum w_i \Delta z_i \\
    \sum w_i \Delta x_i      & \sum w_i \Delta x^2_i & \sum w_i \Delta x_i\Delta y_i & \sum w_i \Delta x_i\Delta z_i \\
    \sum w_i  \Delta y_i     & \sum w_i \Delta x_i\Delta y_i & \sum w_i \Delta y^2_i & \sum w_i \Delta y_i\Delta z_i \\
    \sum w_i  \Delta z_i     & \sum w_i \Delta x_i\Delta z_i & \sum w_i \Delta y_i\Delta z_i & \sum w_i \Delta z^2_i \\
\end{bmatrix}
\, \mathrm{and}\, H = 
\begin{bmatrix}
    w_{1} & w_{2} & \dots  \\
    w_{1}\Delta x_i & w_{2}\Delta x_i &  \dots \\
    w_{1}\Delta y_i & w_{2}\Delta y_i &  \dots \\
    w_{1}\Delta z_i & w_{2}\Delta z_i &  \dots
\end{bmatrix}.}
Since we are interested in $\phi_f$, only the first row of $G^{-1}H$ is of interest, saving computational effort and leaving the final estimate
\Eq{\overline{\phi}_f  = \sum_{i = 1}^N\sum_{k = 1}^o G^{-1}_{1,k} H_{k,i} \phi_i,}
with $o$ given by the desired accuracy of the Taylor approximation (here $o=4$ for the three-dimensional $1^{st}$ order expansion). The weights $w_i$ can be chosen freely, usually as a function of geometrical parameters such as inverse distance or cell volumes (Ref.~\cite{Grande2016}). In Ref.~\cite{Sozer2014}, this method is tested for different 2D meshes with weights $w_i = 1/d_{if}$ as the inverse distance between the face center and the center of cell $i$. Results compare favorably with other unstructured mesh gradient methods and are at least $1^{st}$ order accurate excluding, possibly, numerical rounding errors. 

\subsection*{Calculating the Laplacian}
While the above yields an estimate of the gradient $(\overline{ \bs{\nabla}\phi})_i$ it can easily be extended to an estimated Laplacian using not the Green-Gauss theorem but the divergence theorem:
\Eq{(\overline{ \bs{\nabla}^2\phi})_i  =\frac{1}{V_i} \int_{c_i} dV  \bs{\nabla}^2\phi = \frac{1}{V_i}  \oint_{\partial c_i} dA\, \bs{\nabla}\phi \cdot\, \hat{\bs{n}},}
leading to
\Eq{(\overline{ \bs{\nabla}^2\phi})_i\rightarrow \frac{1}{V_i}\sum_f(\overline{ \bs{\nabla}\phi})_f\cdot\hat{\bs{n}_f}A_f }
for polyhedral cells. Naturally, this requires an estimate of the gradient at the faces, $(\overline{ \bs{\nabla}\phi})_f$, but returning to the linear system of equations of Eq.~\ref{eq:FaceLeastSquares}, we find
\Eq{\overline{\phi}_{f,x}  = \sum_{i = 1}^N\sum_{k = 1}^o G^{-1}_{2,k} H_{k,i} \phi_i,\qquad
       \overline{\phi}_{f,y}  = \sum_{i = 1}^N\sum_{k = 1}^o G^{-1}_{3,k} H_{k,i} \phi_i\quad \mathrm{and}\quad
       \overline{\phi}_{f,z}  = \sum_{i = 1}^N\sum_{k = 1}^o G^{-1}_{4,k} H_{k,i} \phi_i.}
It is at present unclear if this method has been tested in the literature. The above can of course be extended to higher order Taylor approximations and alternative weighting functions. Since $G^{-1}$ is only calculated at the beginning of the procedure, it would very inexpensive to have different weightings $w_{x,i}$, $w_{y,i}$ and $w_{z,i}$ for the different components of the gradient, but as a first foray, $1^{st}$  order Taylor approximations with inverse distance weights should do nicely.
\subsection*{Voronoi diagram automatic strategy}
.
\begin{thebibliography}{19}

\expandafter\ifx\csname natexlab\endcsname\relax\def\natexlab#1{#1}\fi
\expandafter\ifx\csname bibnamefont\endcsname\relax
  \def\bibnamefont#1{#1}\fi
\expandafter\ifx\csname bibfnamefont\endcsname\relax
  \def\bibfnamefont#1{#1}\fi
\expandafter\ifx\csname citenamefont\endcsname\relax
  \def\citenamefont#1{#1}\fi
\expandafter\ifx\csname url\endcsname\relax
  \def\url#1{\texttt{#1}}\fi
\expandafter\ifx\csname urlprefix\endcsname\relax\def\urlprefix{URL }\fi
\providecommand{\bibinfo}[2]{#2}
\providecommand{\eprint}[2][]{\url{#2}}


\bibitem{Sozer2014}
\bibinfo{author}{\bibfnamefont{E. Sozer}},
\bibinfo{author}{\bibfnamefont{C. Brehm}},
\bibnamefont{and}
\bibinfo{author}{\bibfnamefont{C.C. Kiris}},
\emph{\bibinfo{title}{Gradient Calculation Methods on Arbitrary Polyhedral Unstructured Meshes for Cell-Centered CFD Solvers}},
\href{http://dx.doi.org/10.2514/6.2014-1440}{
\bibinfo{journal}{52nd Aerospace Sciences Meeting} 
(\bibinfo{year}{2014}).}


\bibitem{Grande2016}
\bibinfo{author}{\bibfnamefont{D. P{\'{e}}rez-Grande}},
\bibinfo{author}{\bibfnamefont{O. Gonzalez-Martinez}},
\bibinfo{author}{\bibfnamefont{P. Fajardo}},
\bibnamefont{and}
\bibinfo{author}{\bibfnamefont{E. Ahedo}},
\emph{\bibinfo{title}{Analysis of the Numerical Diffusion in Anisotropic Mediums: Benchmarks for Magnetic Field Aligned Meshes in Space Propulsion Simulations}},
\href{https://doi.org/10.3390/app6110354}{
\bibinfo{journal}{Applied Sciences}
\bibinfo{volume}{6}
(\bibinfo{year}{2016}).}





\end{thebibliography}

\end{document}